- [x] Figure out how to use the torch data loader for audio
- [x] Implement M5 model with bells and whistles
- [x] Create training/evaluation script
- [x] Add ml-flow tracking
- [ ] Add some unit tests
- [x] Figure out how to pad audio to make it uniform
- [ ] Implement repeat padding for varying length audios for collate_fn
- [x] Make cross entropy work with the labels
- [x] Figure out why the model isn't training
- [x] Try out original M5 implementation
- [x] Add progress bar for training
- [ ] Address overfitting of the model on training set
- [x] Test my implementation with the existing dataset
- [x] Download meow audio from Audioset
- [x] Look at models that use the Cat Dog dataset
- [x] Log training and validation accuracy of the model in mlflow
- [ ] Run some data analysis on the audioset dataset
- [x] Obtain CatSoundv2 dataset
- [ ] Create another training pipeline that uses spectrograms instead
- [ ] Create inference script
- [x] Train classifier on cat sound dataset
- [ ] Refactor everything so less side logic
- [x] Ensure no data leakage in the validation set with the augmented cat sounds
- [x] Check what augmentation is being applied to the audio
- [x] Re-implement data augmentation with librosa
